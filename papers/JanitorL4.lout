@SysInclude { report }
@SysInclude { eq }


@Database @Reference { refs }
def @GCT { GCT }
def @L4 { L4::Pistachio }

@Report
@DateLine { Yes }
@Title {
A Lightweight Garbage Collector for the L4 Microkernel
}
@Author { Gabor Greif }
@Institution { @F gabor@mac.com }
@AbstractDisplay { Yes }
@Abstract {
We present the design of a small and performant
exact garbage collector for the @L4
microkernel. In its first incarnation the mark-and-sweep
collection strategy is supported, but
in principle other strategies like compacting and
hybrid strategies are also conceivable. This
flexibility is due to the declarative way how
the layout of the managed objects is communicated
to the collector. A dedicated L4 thread is responsible
for all memory management of client threads but
it is guaranteed that nonrelated threads cannot obtain
access to each other's objects, ensuring privacy.
}
//

##################################
##################################
##################################
@Section
@Title { Structure of the Document }
@Begin
@PP
In this design document we briefly introduce the
abstraction concepts provided by the @L4
microkernel, and immediately delve into the high
level ideas behind the garbage collector that builds
on these abstractions. We thereafter present a typical
scenario how a client interacts wit the garbage server.
Later sections dissect each aspect of the design down
to the finer aspects and implementation details.
Finally we summarize what has been reached.
@End @Section

##################################
##################################
##################################
@Section
@Title { Introduction }
@Begin
@PP
We start out by recalling the concepts that allow us
to regard the @L4 microkernel as a modern abstract
CPU. Thereafter we dedicate some room to the
description of the workings of a simple mark-and-sweep
garbage collector that has the exact tracing property.

#################
@BeginSubSections

###########
@SubSection @Title { L4 Concepts }
@Begin
@PP
The minimalistic microkernels of the L4 family @Cite { $l4whitepaper }
just try to provide the services that the average modern CPU
possess, but in a portable, yet efficient way. The L4 reference manual
{ $l4ref } mentions {@I threads}, {@I scheduling}, @I { address spaces },
@I { interprocess communication } as the main abstractions and describes
means of manipulating these, along with standardized ways of how to obtain
configuration information. We now briefly visit each of these abstractions.

#################
@BeginSubSubSections

###########
@SubSubSection @Title { Threads }
@Begin
@PP
L4 threads roughly correspond to the program counter (PC) and
stack pointer (SP) of the average CPU. An executing thread
actually possesses one of the computers real processors.

@End @SubSubSection

###########
@SubSubSection @Title { Scheduling }
@Begin
@PP
Scheduling in L4 is a abstraction to assign real processors
to L4 threads in a simple timeslice based manner. This
can be regarded as an analog of a CPUs interrupt mechanism.

@End @SubSubSection

###########
@SubSubSection @Title { Address Spaces and Mapping }
@Begin
@PP
The MMU (memory management unit) of ordinary processors provides
the basis for demand paged memory management. In L4 this functionality
is covered by @I {address spaces}, parts of whose can be @I mapped
(shared) between them.

@End @SubSubSection

###########
@SubSubSection @Title { IPC }
@Begin
@PP
L4 IPC is an asyncronous means of invoking functionality in other threads
an passing information between them.

@End @SubSubSection

@EndSubSubSections
@End @SubSection

###########
@SubSection @Title { Garbage Collection Concepts }
@Begin
@PP
mark-and-sweep
exact
@End @SubSection

###########
@SubSection @Title { WHAT??? }
@Begin
@PP


@End @SubSection

@EndSubSections

@End @Section

##################################
##################################
##################################
@Section
@Title { A Client-Server Exchange  }
@Begin
@PP
Armed with the definitions of the previous section
we can begin a thought experiment how a client-server
interaction could look like at an intuitive level.

For the purpose of this experiment we reduce our
pretension to handle small, uniform objects, as
known from the Scheme @Cite { $r5rs }
and Lisp @Cite { $ansilisp } languages: @I { cons
cells }. A cons cell is a data stucture that can
hold two pointers, by convention the first one
points to some @I payload, the second to another
cons cell. This construction principle allows the
building of linked lists, but also arbitrarily
complex data. Of course the first cons cell ever
to be created cannot hold other pointers other than
to itself (let's restrict ourselves to creation one
cell at a time), we will treat this distinguished
object @I {Êthe empty list }. At this stage we
already can construct arbitrarily nested lists,
for some mildly interesting examples see figure XXXX.
When we allow setting the head or tail of the cons
cells (their first resp. second pointer) we can even
build @I { circular lists } by letting the tail of
the second cell point to the first cell.
To make our object zoo less boring we add primitive
objects to the mix: @I { fixed-bitwidth integers }.
Assuming machine pointers adher to certain alignment
restrictions (say, they can only point to even memory
locations) we can represent integers as @I {Ênon-proper
pointers } where the least significant bit is set.



@End @Section

##################################
##################################
##################################
@Section
@Title { Lightweight Garbage Collector }
@Begin
@PP
After we have obtained some understanding of what
garbage collection is all about, our task is now to
build a conceptual model that uses L4 as its foundation.

#################
@BeginSubSections

###########
@SubSection @Title { Thread Model }
@Begin
@PP
A single thread per system is responsible for each garbage
collecting related activity. This thread is called @GCT and
directly communicates with the L4 memory pool thread
(@Eq {sigma sub 0} ???) to acquire memory pages. Application
threads (directly or indirectly) register with @GCT as their
pager thread. @GCT will accept IPC requests that contain
a layout descriptor and a memory range. Upon completion
requested memory range will be ready for populating with
objects of the specified layout.
@End @SubSection

###########
@SubSection @Title { Paging }
@Begin
@PP
However the pages will not
yet be allocated in this range, only the first write access
in a page will actually make the page present. An initial read
access will be treated as an error. This paging activity will be
the standard L4 one. When the demand paging thread decides to
page out any populated page(s), it will create a compacted representation
of all outward pointers in the page(s), so that an eventual
collection won't require a page-in to follow pointers.
@End @SubSection

###########
@SubSection @Title { Layout Declarations }
@Begin
@PP
The secret behind the performance of the collector is the
fact that the layout of the populated pages is communicated
to the @GCT. The layout declarations consist of the object
size and a list of pairs. The first component of a pair is
an offset that identifies a pointer inside of an object.
The second component of a pair is a bitfield containing flags
specifying properties of this pointer (e.g. whether it may be
a null pointer).
@End @SubSection

###########
@SubSection @Title { Object Allocation }
@Begin
@PP

interaction with threads
@End @SubSection

###########
@SubSection @Title { Roots }
@Begin
@PP
@End @SubSection

###########
@SubSection @Title { Collection }
@Begin
@PP

@End @SubSection

###########
@SubSection @Title { Starving of Threads }
@Begin
@PP

@End @SubSection


@EndSubSections


@End @Section


##################################
##################################
##################################
@Section
@Title { Implementation Details }
@Begin
@PP
Some random issues need to be clarified to
obtain a system that is generally usable.
The following issues will focus on specific
aspects of the design without an obvious
oder or thematical interconnections.

#################
@BeginSubSections

###########
@SubSection @Title { Locks }
@Begin
@PP
@End @SubSection

###########
@SubSection @Title { Object Visibility }
@Begin
@PP
@End @SubSection

###########
@SubSection @Title { Layout Hints }
@Begin
@PP
@End @SubSection

###########
@SubSection @Title { Compiling Layout }
@Begin
@PP
@End @SubSection

###########
@SubSection @Title { Security }
@Begin
@PP
@End @SubSection



@EndSubSections
@End @Section



##################################
##################################
##################################
@Section
@Title { Future Work }
@Begin
@PP
The mentioned mechanisms can be performance tuned by some
features not yet described in the literature (???). Such
features include the exchange of trusted code that performs
marking or compacting. Ideally the exchange of worker code
is controlled by a third server that utilizes cryptographic
signatures and is able to verify termination properties of
the worker code. Injecting code from the client into the
server allows executing of marking code inside of the server
avoiding any context switches mandated by IPC with all positive
effects on cache utilization and runtime overhead.

@PP
UnMap events could be used to notify clients about the fact that
a flexpage is about to be withdrawn. This could trigger a compaction
or precollection of all outgoing references.
@End @Section


##################################
##################################
##################################
@Section
@Title { Summary }
@Begin
@PP
@End @Section


##################################
##################################
##################################
@Section
@Title { Thanks }
@Begin
@PP

@End @Section


##################################
##################################
##################################
@Section
@Title { Bibliography }
@Begin
@PP
The SawMill Multiserver Approach
@End @Section


##################################
##################################
##################################
@Appendix
@Title { The Garbage Server IPC Interface }
@Begin
@PP
The @L4 server providing the automatic memory management
facilities is called @I { Garbage Server } because its
main purpose is to provide uninitialized memory locations
to its clients and reclaim back some of the garbage the
client accumulated at periodic intervals.
@PP
The below interfaces will be given in IDL style along with
description of their arguments, purpose and side-effects.

###########
@SubAppendix @Title { IPC call @F allocate }
@Begin
@PP
@Argument
  name: metaPage
  type: FlexPage
  { Specifies a flexpage where the metadata for the requested flexpages should go.
     }
@Argument
  name: sizeInOctets
  type: size_t
  { Specifies the amount of garbage that is requested by the client.
     }
@Purpose
{ @F allocate shall reply with a (not necessarily contiguous) range of flexpages
  in sum covering  @F sizeInOctets octets of garbage. }
@SideEffects
{ @F allocate shall zero out the metadata corresponding to the returned flexpages
  in the flexpage pointed to by @F {metaPage}. }

@End @SubAppendix

###########
@SubAppendix @Title { IPC call @F collect }
@Begin
@PP
@Argument
  name: metaPage
  type: FlexPage
  { Specifies a flexpage where the metadata for the requested flexpages should go.
     }
@Argument
  name: sizeInOctets
  type: size_t
  { Specifies the amount of garbage that is requested by the client.
     }
@Purpose
{ @F allocate shall reply with a (not necessarily contiguous) range of flexpages
  in sum covering  @F sizeInOctets octets of garbage. }
@SideEffects
{ @F allocate shall zero out the metadata corresponding to the returned flexpages
  in the flexpage pointed to by @F { metaPage }. }

@End @SubAppendix



@EndSubAppendices
@End @Appendix


