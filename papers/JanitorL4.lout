@SysInclude { report }
@SysInclude { eq }


@Database @Reference { refs }
def @GCT { GCT }
def @L4 { L4::Pistachio }

@Report
@DateLine { Yes }
@Title {
A Lightweight Garbage Collector for the L4 Microkernel
}
@Author { Gabor Greif }
@Institution { @F gabor@mac.com }
@AbstractDisplay { Yes }
@Abstract {
We present the design of a small and performant
exact garbage collector for the @L4
microkernel. In its first incarnation the mark-and-sweep
collection strategy is supported, but
in principle other strategies like compacting and
hybrid strategies are also conceivable. This
flexibility is due to the declarative way how
the layout of the managed objects is communicated
to the collector. A dedicated L4 thread is responsible
for all memory management of client threads but
it is guaranteed that nonrelated threads cannot obtain
access to each other's objects, ensuring privacy.
}
//

##################################
##################################
##################################
@Section
@Title { Structure of the Document }
@Begin
@PP
In this design document we briefly introduce the
abstraction concepts provided by the @L4
microkernel, and immediately delve into the high
level ideas behind the garbage collector that builds
on these abstractions. We thereafter present a typical
scenario how a client interacts wit the garbage server.
Later sections dissect each aspect of the design down
to the finer aspects and implementation details.
Finally we summarize what has been reached.
@End @Section

##################################
##################################
##################################
@Section
@Title { Introduction }
@Begin
@PP
We start out by recalling the concepts that allow us
to regard the @L4 microkernel as a modern abstract
CPU. Thereafter we dedicate some room to the
description of the workings of a simple mark-and-sweep
garbage collector that has the exact tracing property.

#################
@BeginSubSections

###########
@SubSection @Title { L4 Concepts }
@Begin
@PP
The minimalistic microkernels of the L4 family @Cite { $l4whitepaper }
just try to provide the services that the average modern CPU
possess, but in a portable, yet efficient way. The L4 reference manual
{ $l4ref } mentions {@I threads}, {@I scheduling}, @I { address spaces },
@I { interprocess communication } as the main abstractions and describes
means of manipulating these, along with standardized ways of how to obtain
configuration information. We now briefly visit each of these abstractions.

#################
@BeginSubSubSections

###########
@SubSubSection @Title { Threads }
@Begin
@PP
L4 threads roughly correspond to the program counter (PC) and
stack pointer (SP) of the average CPU. An executing thread
actually possesses one of the computers real processors.

@End @SubSubSection

###########
@SubSubSection @Title { Scheduling }
@Begin
@PP
Scheduling in L4 is a abstraction to assign real processors
to L4 threads in a simple timeslice based manner. This
can be regarded as an analog of a CPUs interrupt mechanism.

@End @SubSubSection

###########
@SubSubSection @Title { Address Spaces and Mapping }
@Begin
@PP
The MMU (memory management unit) of ordinary processors provides
the basis for demand paged memory management. In L4 this functionality
is covered by @I {address spaces}, parts of whose can be @I mapped
(shared) between them.

@End @SubSubSection

###########
@SubSubSection @Title { IPC }
@Begin
@PP
L4 IPC is an asyncronous means of invoking functionality in other threads
an passing information between them.

@End @SubSubSection

@EndSubSubSections
@End @SubSection

###########
@SubSection @Title { Garbage Collection Concepts }
@Begin
@PP
mark-and-sweep
exact
@End @SubSection

###########
@SubSection @Title { WHAT??? }
@Begin
@PP


@End @SubSection

@EndSubSections

@End @Section

##################################
##################################
##################################
@Section
@Title { A Client-Server Exchange  }
@Begin
@PP
Armed with the definitions of the previous section
we can begin a thought experiment how a client-server
interaction could look like at an intuitive level.

@PP
For the purpose of this experiment we reduce our
pretension to handle small, uniform objects, as
known from the Scheme @Cite { $r5rs }
and Lisp @Cite { $ansilisp } languages: @I { cons
cells }. A cons cell is a data stucture that can
hold two pointers, by convention the first one
points to some @I payload, the second to another
cons cell. This construction principle allows the
building of linked lists, but also arbitrarily
complex data. Of course the first cons cell ever
to be created cannot hold other pointers other than
to itself (let's restrict ourselves to creation one
cell at a time), we will treat this distinguished
object @I {Êthe empty list }. At this stage we
already can construct arbitrarily nested lists,
for some mildly interesting examples see figure XXXX.
When we allow setting the head or tail of the cons
cells (their first resp. second pointer) we can even
build @I { circular lists } by letting the tail of
the second cell point to the first cell.
To make our object zoo less boring we add primitive
objects to the mix: @I { fixed-bitwidth integers }.
Assuming machine pointers adher to certain alignment
restrictions (say, they can only point to even memory
locations) we can represent integers as @I {Ênon-proper
pointers } where the least significant bit is set.

@PP
How will an application program (a client) obtain any
any memory from the garbage server for @I { consing }?
Before we evaluate an answer let's consider a specific
layout for the (object-)data and the data holding
supplementary information about its properties which
we call @I { metadata }. Let there be a fixed relation of
pointers that assigns a metadata pointer to each
object data pointer. This relation will determine
how much metadata will be associated with each
object pointer or a range of object pointers.
Figure XXXX illustrates a possible relation, 
we obtain the metadata pointer @Eq { P'' } for an object
pointer @Eq { P } by rounding downward to a @Eq { 2 up n }
boundary (giving @Eq { P' }) and offsetting by
@Eq { P - P' div 2 up m }. Naturally, such a relation
assigns the same metadata pointer to a range of object
pointers, which might be beneficial when that range
of objects is intended to be supported by identical
metadata anyway. Another consequence of such a relation
is that the size of the flexpages imply certain values
for @Eq { m } and @Eq { n }. A discussion of the meaningful
values can be found in the appendix. Furthermore
the relation also determines which flexpages can serve
as metadata for flexpages containing object data.

@PP
Now that we have defined a @I { metadata relation }, we
can try to give meaning to the metadata associated with
object data. Since we discuss exact garbage collection,
we unsurprisingly utilize (a part of) the metadata for
storing @I { layout information } in it, that is interpreted
by the garbage server. Other conceivable use for the metadata
might be @I { type information } that is common for all objects
in the pointer range @Footnote
    { The @I { Gwydion Dylan } implementation of the
    @I { Dylan } programming language @Cite { $DRM }
    always stores a @I { class pointer } at offset zero
    of each object. These could be moved to the metadata,
    reducing the size of each individual object. }.

@PP
How can the garbage server be helpful to any client in
this scheme? First the client has to acquire a metadata
flexpage from the server by invoking its @F metallocate
interface specifying its size and the metadata relation.
But metadata flexpages are not intended for storing
objects @Footnote
    { Metadata flexpages may still store metaobjects
    which may be governed by another metadata relation
    and meta-metadata. },
so another invocation of a server interface (@ { allocate })
is required to obtain a number of object flexpages all
sharing a specified metadata flexpage (@I metapage for short).
This invocation takes the net size of desired objects, the
metadata relation and passes back object flexpages
(@I objectpages for short) to the client. The metadata
corresponding to the objectpages gets cleared out in the
process, effectively marking the objectpages as garbage.
The garbage server is allowed to not fully satisfy the
request and in an extreme case not to pass back any
objectpages. This can be a necessity to enforce the
client's quotas and prevent thrashing.

@PP
When the client has consumed all the garbage in the objectpages
it obtained earlier, it invokes the @F collect interface of the
server, which initiates a garbage collection.

>>>>> Draining, Marking, etc.

@End @Section

##################################
##################################
##################################
@Section
@Title { Lightweight Garbage Collector }
@Begin
@PP
After we have obtained some understanding of what
garbage collection is all about, our task is now to
build a conceptual model that uses L4 as its foundation.

#################
@BeginSubSections

###########
@SubSection @Title { Thread Model }
@Begin
@PP
A single thread per system is responsible for each garbage
collecting related activity. This thread is called @GCT and
directly communicates with the L4 memory pool thread
(@Eq {sigma sub 0} ???) to acquire memory pages. Application
threads (directly or indirectly) register with @GCT as their
pager thread. @GCT will accept IPC requests that contain
a layout descriptor and a memory range. Upon completion
requested memory range will be ready for populating with
objects of the specified layout.
@End @SubSection

###########
@SubSection @Title { Paging }
@Begin
@PP
However the pages will not
yet be allocated in this range, only the first write access
in a page will actually make the page present. An initial read
access will be treated as an error. This paging activity will be
the standard L4 one. When the demand paging thread decides to
page out any populated page(s), it will create a compacted representation
of all outward pointers in the page(s), so that an eventual
collection won't require a page-in to follow pointers.
@End @SubSection

###########
@SubSection @Title { Layout Declarations }
@Begin
@PP
The secret behind the performance of the collector is the
fact that the layout of the populated pages is communicated
to the @GCT. The layout declarations consist of the object
size and a list of pairs. The first component of a pair is
an offset that identifies a pointer inside of an object.
The second component of a pair is a bitfield containing flags
specifying properties of this pointer (e.g. whether it may be
a null pointer).
@End @SubSection

###########
@SubSection @Title { Object Allocation }
@Begin
@PP

interaction with threads
@End @SubSection

###########
@SubSection @Title { Roots }
@Begin
@PP
@End @SubSection

###########
@SubSection @Title { Collection }
@Begin
@PP

@End @SubSection

###########
@SubSection @Title { Starving of Threads }
@Begin
@PP

@End @SubSection


@EndSubSections


@End @Section


##################################
##################################
##################################
@Section
@Title { Implementation Details }
@Begin
@PP
Some random issues need to be clarified to
obtain a system that is generally usable.
The following issues will focus on specific
aspects of the design without an obvious
oder or thematical interconnections.

#################
@BeginSubSections

###########
@SubSection @Title { Locks }
@Begin
@PP
@End @SubSection

###########
@SubSection @Title { Object Visibility }
@Begin
@PP
@End @SubSection

###########
@SubSection @Title { Layout Hints }
@Begin
@PP
@End @SubSection

###########
@SubSection @Title { Compiling Layout }
@Begin
@PP
@End @SubSection

###########
@SubSection @Title { Security }
@Begin
@PP
@End @SubSection



@EndSubSections
@End @Section



##################################
##################################
##################################
@Section
@Title { Future Work }
@Begin
@PP
The mentioned mechanisms can be performance tuned by some
features not yet described in the literature (???). Such
features include the exchange of trusted code that performs
marking or compacting. Ideally the exchange of worker code
is controlled by a third server that utilizes cryptographic
signatures and is able to verify termination properties of
the worker code. Injecting code from the client into the
server allows executing of marking code inside of the server
avoiding any context switches mandated by IPC with all positive
effects on cache utilization and runtime overhead.

@PP
UnMap events could be used to notify clients about the fact that
a flexpage is about to be withdrawn. This could trigger a compaction
or precollection of all outgoing references.
@PP
Pre-reservations of a range of pointers, spanning many potentially
initialized objects, the reservation gets renewed on collection
(to a hopefully less initialized range) ranging over the remaining
allocation size.
@PP
On multiprocessors use a scheme involving processor numbers to avoid
range or allocation collisions.
@End @Section


##################################
##################################
##################################
@Section
@Title { Summary }
@Begin
@PP
@End @Section


##################################
##################################
##################################
@Section
@Title { Thanks }
@Begin
@PP

@End @Section


##################################
##################################
##################################
@Section
@Title { Bibliography }
@Begin
@PP
The SawMill Multiserver Approach
@End @Section


##################################
##################################
##################################
@Appendix
@Title { The Garbage Server IPC Interface }
@Begin
@PP
The @L4 server providing the automatic memory management
facilities is called @I { Garbage Server } because its
main purpose is to provide uninitialized memory locations
to its clients and reclaim back some of the garbage the
client accumulated at periodic intervals.
@PP
The below interfaces will be given in IDL style along with
description of their arguments, purpose and side-effects.

###########
@SubAppendix @Title { IPC call @F allocate }
@Begin
@PP
@Argument
  name: metaPage
  type: FlexPage
  { Specifies a flexpage where the metadata for the requested flexpages should go.
     }
@Argument
  name: sizeInOctets
  type: size_t
  { Specifies the amount of garbage that is requested by the client.
     }
@Purpose
{ @F allocate shall reply with a (not necessarily contiguous) range of flexpages
  in sum covering  @F sizeInOctets octets of garbage. }
@SideEffects
{ @F allocate shall zero out the metadata corresponding to the returned flexpages
  in the flexpage pointed to by @F {metaPage}. }

@End @SubAppendix

###########
@SubAppendix @Title { IPC call @F collect }
@Begin
@PP
@Argument
  name: metaPage
  type: FlexPage
  { Specifies a flexpage where the metadata for the requested flexpages should go.
     }
@Argument
  name: sizeInOctets
  type: size_t
  { Specifies the amount of garbage that is requested by the client.
     }
@Purpose
{ @F allocate shall reply with a (not necessarily contiguous) range of flexpages
  in sum covering  @F sizeInOctets octets of garbage. }
@SideEffects
{ @F allocate shall zero out the metadata corresponding to the returned flexpages
  in the flexpage pointed to by @F { metaPage }. }

@End @SubAppendix



@EndSubAppendices
@End @Appendix


